{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f35859-f00f-4327-9cee-d0eca87d2efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.10 environment at: /home/m/priv/opencv/4.11.0-Release/venv-py3\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m                                            \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 1.14s\u001b[0m\u001b[0m                                              \n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 0.90ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 0.78ms\u001b[0m\u001b[0m:///home/m/priv/opencv/ml/Artic\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mlib8\u001b[0m\u001b[2m==0.0.1 (from file:///home/m/priv/opencv/ml/ArticleKarma/w2v)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "!uv pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47c791ed-ad6f-4388-b6d4-0bcfe0075526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Switched to eval mode. Pre-warming cache... ---\n",
      "--- Calculating and caching normalized embeddings... ---\n",
      "--- Using cached embeddings. ---\n",
      "tensor([ 1.0131, -2.2534,  2.9557,  1.0012, -2.8855,  1.0694, -1.9559,  0.6893,\n",
      "        -0.2117, -0.6307,  0.4645,  2.6286, -0.3848,  1.5738,  1.3697,  0.9492,\n",
      "         0.7929, -0.4674,  0.4990, -0.5125, -0.4253,  0.4997, -0.4889,  1.8631,\n",
      "        -2.5101, -0.6762,  2.1135,  0.3309, -0.9120,  0.4431, -0.1341, -0.5134,\n",
      "         2.0929,  0.6448,  0.6758,  1.1500, -0.7588,  1.0896, -0.5671, -0.1161,\n",
      "        -1.1667, -0.5457, -0.6286, -0.6150, -1.2098, -2.5519, -1.3874, -0.5012,\n",
      "        -0.2623, -0.4730])\n",
      "--- Using cached embeddings. ---\n",
      "------------------------------\n",
      "vienna               0.8102\n",
      "paris                0.7615\n",
      "germany              0.7397\n",
      "berlin               0.5969\n",
      "stuttgart            0.5816\n",
      "hamburg              0.5750\n",
      "pres                 0.5674\n",
      "bonn                 0.5620\n",
      "fribourg             0.5565\n",
      "ttingen              0.5453\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from lib8 import stream_sentences, Word2Vec, create_skipgram_generator, create_skipgram_batch_generator\n",
    "import torch\n",
    "\n",
    "embedding_dim = 50\n",
    "device_ids = [0, 1] # Use the first two GPUs\n",
    "device = torch.device(f\"cuda:{device_ids[0]}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Initialize Model, Loss, and Optimizer ---\n",
    "MODEL_PATH = f\"word2vec_pytorch_{embedding_dim}.pth\"\n",
    "\n",
    "model = Word2Vec.load_from_checkpoint(MODEL_PATH, device)\n",
    "model.eval()\n",
    "\n",
    "# Example usage:\n",
    "similar_words = model.find_most_similar('germany', top_n=10)\n",
    "# similar_words = model.find_most_similar('computer', top_n=10)\n",
    "\n",
    "p = model.get_vector('paris')\n",
    "f = model.get_vector('france')\n",
    "g = model.get_vector('germany')\n",
    "\n",
    "bgf = p - f + g\n",
    "print(bgf)\n",
    "similar_words = model.find_most_similar_by_vector(bgf, top_n=10)\n",
    "\n",
    "if similar_words:\n",
    "    print(\"-\" * 30)\n",
    "    for word, score in similar_words:\n",
    "        print(f\"{word:<20} {score:.4f}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0b1147-6fa0-4c63-a6fa-9e659e86ee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "------------------------------4\n",
    "system               0.9449\n",
    "program              0.9440\n",
    "standard             0.9371\n",
    "design               0.9325\n",
    "other                0.9299\n",
    "music                0.9292\n",
    "like                 0.9292\n",
    "include              0.9291\n",
    "information          0.9254\n",
    "modern               0.9249\n",
    "------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
