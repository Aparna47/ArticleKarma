{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 4,
=======
   "execution_count": 1,
>>>>>>> Stashed changes
   "id": "02f35859-f00f-4327-9cee-d0eca87d2efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
=======
>>>>>>> Stashed changes
      "Processing /Users/aparna/ArticleKarma/w2v\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: lib8\n",
      "  Building wheel for lib8 (pyproject.toml) ... \u001b[?25ldone\n",
<<<<<<< Updated upstream
      "\u001b[?25h  Created wheel for lib8: filename=lib8-0.0.1-py3-none-any.whl size=4726 sha256=f84951793d7622ff55e7be3e1778c65514394c1e82893186994c1b13196c84b2\n",
      "  Stored in directory: /private/var/folders/vw/l06k308d54n8_9gm54qps8340000gn/T/pip-ephem-wheel-cache-jho1ovnl/wheels/12/e3/29/9877cf22306c90fc6412b84f1067e47f384afba536b12a1c7c\n",
      "Successfully built lib8\n",
      "Installing collected packages: lib8\n",
      "  Attempting uninstall: lib8\n",
      "    Found existing installation: lib8 0.0.1\n",
      "    Uninstalling lib8-0.0.1:\n",
      "      Successfully uninstalled lib8-0.0.1\n",
=======
      "\u001b[?25h  Created wheel for lib8: filename=lib8-0.0.1-py3-none-any.whl size=3845 sha256=118c11b968f33aa50d12d91426e073ad9a638d333a04a42d3871277f860aac4d\n",
      "  Stored in directory: /private/var/folders/vw/l06k308d54n8_9gm54qps8340000gn/T/pip-ephem-wheel-cache-ur8qj1tp/wheels/12/e3/29/9877cf22306c90fc6412b84f1067e47f384afba536b12a1c7c\n",
      "Successfully built lib8\n",
      "Installing collected packages: lib8\n",
>>>>>>> Stashed changes
      "Successfully installed lib8-0.0.1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "!pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47c791ed-ad6f-4388-b6d4-0bcfe0075526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Switched to eval mode. Pre-warming cache... ---\n",
      "--- Calculating and caching normalized embeddings... ---\n",
      "--- Using cached embeddings. ---\n",
      "tensor([ 1.0206, -2.2515,  2.9227,  0.9936, -2.8610,  1.0498, -1.9977,  0.7343,\n",
      "        -0.2055, -0.6151,  0.4477,  2.6032, -0.3928,  1.5864,  1.3785,  0.9484,\n",
      "         0.8003, -0.4182,  0.5179, -0.5204, -0.3343,  0.4788, -0.4805,  1.8474,\n",
      "        -2.4722, -0.6135,  2.1048,  0.3166, -0.9847,  0.4622, -0.0520, -0.5180,\n",
      "         2.0715,  0.6134,  0.5984,  1.0649, -0.7953,  1.0343, -0.5519, -0.1473,\n",
      "        -1.1313, -0.5440, -0.5994, -0.6517, -1.2138, -2.5281, -1.3109, -0.5043,\n",
      "        -0.2354, -0.5100])\n",
      "--- Using cached embeddings. ---\n",
      "------------------------------\n",
<<<<<<< Updated upstream
      "vienna               0.8103\n",
      "paris                0.7618\n",
      "germany              0.7410\n",
      "berlin               0.6080\n",
      "stuttgart            0.5881\n",
      "hamburg              0.5814\n",
      "bonn                 0.5726\n",
      "pres                 0.5667\n",
      "fribourg             0.5655\n",
      "zurich               0.5484\n",
=======
      "king                 0.7225\n",
      "iii                  0.6709\n",
      "france               0.6577\n",
      "germany              0.5895\n",
      "charles              0.5785\n",
      "james                0.5761\n",
      "henry                0.5734\n",
      "iv                   0.5727\n",
      "v                    0.5634\n",
      "battle               0.5631\n",
>>>>>>> Stashed changes
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from lib8 import stream_sentences, Word2Vec, create_skipgram_generator, create_skipgram_batch_generator\n",
    "import torch\n",
    "\n",
    "embedding_dim = 50\n",
    "device_ids = [0, 1] # Use the first two GPUs\n",
    "device = torch.device(f\"cuda:{device_ids[0]}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Initialize Model, Loss, and Optimizer ---\n",
    "MODEL_PATH = f\"word2vec_pytorch_{embedding_dim}.pth\"\n",
    "\n",
    "model = Word2Vec.load_from_checkpoint(MODEL_PATH, device)\n",
    "model.eval()\n",
    "\n",
    "# Example usage:\n",
    "similar_words = model.find_most_similar('ii', top_n=10)\n",
    "# similar_words = model.find_most_similar('computer', top_n=10)\n",
    "\n",
    "p = model.get_vector('paris')\n",
    "f = model.get_vector('france')\n",
    "g = model.get_vector('germany')\n",
    "\n",
    "bgf = p - f + g\n",
    "print(bgf)\n",
    "similar_words = model.find_most_similar_by_vector(bgf, top_n=10)\n",
    "\n",
    "if similar_words:\n",
    "    print(\"-\" * 30)\n",
    "    for word, score in similar_words:\n",
    "        print(f\"{word:<20} {score:.4f}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0b1147-6fa0-4c63-a6fa-9e659e86ee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "------------------------------4\n",
    "system               0.9449\n",
    "program              0.9440\n",
    "standard             0.9371\n",
    "design               0.9325\n",
    "other                0.9299\n",
    "music                0.9292\n",
    "like                 0.9292\n",
    "include              0.9291\n",
    "information          0.9254\n",
    "modern               0.9249\n",
    "------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
