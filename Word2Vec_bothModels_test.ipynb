{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb4cbe9-3c0a-4978-9b34-b7c8f26201a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import logging\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2b6ce31-bd0e-48d3-b740-484cc6eae97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configure Logging\n",
    "# This helps to see the training progress and any warnings/errors from gensim\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4542e3ff-49b9-4aeb-a22f-d8a8ca2231d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text8_filename = '~/Documents/MLX/text8'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c91fede0-f785-4661-b97b-263a4161ed92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text loaded into pandas object. Type: <class 'pandas.core.series.Series'>. Shape: (1,)\n",
      "First 3 lines from pandas object:\n",
      "0     anarchism originated as a term of abuse first...\n",
      "Name: text_content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Read each line as a separate row in a DataFrame/Series\n",
    "    # header=None means no header row\n",
    "    # names=['text_content'] assigns a column name\n",
    "    # squeeze=True attempts to return a Series if only one column results\n",
    "    df_temp = pd.read_csv(text8_filename, header=None, names=['text_content'], encoding='utf-8')\n",
    "    \n",
    "    # Check if the DataFrame has exactly one column. If so, convert it to a Series.\n",
    "    # This replaces the deprecated 'squeeze=True' functionality.\n",
    "    if df_temp.shape[1] == 1:\n",
    "        df_text = df_temp['text_content']\n",
    "    else:\n",
    "        df_text = df_temp # Keep as DataFrame if multiple columns, though unlikely for text8\n",
    "\n",
    "    print(f\"\\nText loaded into pandas object. Type: {type(df_text)}. Shape: {df_text.shape}\")\n",
    "    print(\"First 3 lines from pandas object:\")\n",
    "    print(df_text.head(3))\n",
    "except FileNotFoundError:\n",
    "    logging.error(f\"Error: The file '{text8_filename}' was not found. Please ensure it's in the correct directory.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred while loading the file with pandas: {e}\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc0368f2-ee6f-42d8-9d8f-53d06a8c0ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_for_gensim = df_text.apply(lambda x: x.lower().split()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d28c4cdf-253e-4d5f-a3b4-4ef37009b24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 1 sentences for gensim.\n",
      "Example of processed sentence (first one):\n",
      "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against', 'early', 'working', 'class', 'radicals', 'including', 'the', 'diggers', 'of', 'the', 'english']\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nProcessed {len(sentences_for_gensim)} sentences for gensim.\")\n",
    "print(\"Example of processed sentence (first one):\")\n",
    "print(sentences_for_gensim[0][:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a9da4f5-4719-4234-84f8-a7d27992b50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 14:50:27,651 : INFO : collecting all words and their counts\n",
      "2025-06-10 14:50:27,653 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting CBOW model training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 14:50:28,533 : INFO : collected 253854 word types from a corpus of 17005207 raw words and 1 sentences\n",
      "2025-06-10 14:50:28,533 : INFO : Creating a fresh vocabulary\n",
      "2025-06-10 14:50:28,762 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 253854 unique words (100.00% of original 253854, drops 0)', 'datetime': '2025-06-10T14:50:28.762928', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2025-06-10 14:50:28,763 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 17005207 word corpus (100.00% of original 17005207, drops 0)', 'datetime': '2025-06-10T14:50:28.763221', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2025-06-10 14:50:29,066 : INFO : deleting the raw counts dictionary of 253854 items\n",
      "2025-06-10 14:50:29,068 : INFO : sample=0.001 downsamples 36 most-common words\n",
      "2025-06-10 14:50:29,069 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 12819131.785650097 word corpus (75.4%% of prior 17005207)', 'datetime': '2025-06-10T14:50:29.069195', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2025-06-10 14:50:29,570 : INFO : estimated required memory for 253854 words and 100 dimensions: 330010200 bytes\n",
      "2025-06-10 14:50:29,571 : INFO : resetting layer weights\n",
      "2025-06-10 14:50:29,658 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-06-10T14:50:29.658055', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'build_vocab'}\n",
      "2025-06-10 14:50:29,658 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 253854 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-06-10T14:50:29.658399', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'train'}\n",
      "2025-06-10 14:50:29,675 : INFO : EPOCH 0: training on 17005207 raw words (10000 effective words) took 0.0s, 601603 effective words/s\n",
      "2025-06-10 14:50:29,688 : INFO : EPOCH 1: training on 17005207 raw words (10000 effective words) took 0.0s, 825159 effective words/s\n",
      "2025-06-10 14:50:29,701 : INFO : EPOCH 2: training on 17005207 raw words (10000 effective words) took 0.0s, 1016678 effective words/s\n",
      "2025-06-10 14:50:29,715 : INFO : EPOCH 3: training on 17005207 raw words (10000 effective words) took 0.0s, 840068 effective words/s\n",
      "2025-06-10 14:50:29,727 : INFO : EPOCH 4: training on 17005207 raw words (10000 effective words) took 0.0s, 880954 effective words/s\n",
      "2025-06-10 14:50:29,739 : INFO : EPOCH 5: training on 17005207 raw words (10000 effective words) took 0.0s, 887466 effective words/s\n",
      "2025-06-10 14:50:29,752 : INFO : EPOCH 6: training on 17005207 raw words (10000 effective words) took 0.0s, 1040114 effective words/s\n",
      "2025-06-10 14:50:29,763 : INFO : EPOCH 7: training on 17005207 raw words (10000 effective words) took 0.0s, 931474 effective words/s\n",
      "2025-06-10 14:50:29,775 : INFO : EPOCH 8: training on 17005207 raw words (10000 effective words) took 0.0s, 1055799 effective words/s\n",
      "2025-06-10 14:50:29,787 : INFO : EPOCH 9: training on 17005207 raw words (10000 effective words) took 0.0s, 914537 effective words/s\n",
      "2025-06-10 14:50:29,798 : INFO : EPOCH 10: training on 17005207 raw words (10000 effective words) took 0.0s, 928627 effective words/s\n",
      "2025-06-10 14:50:29,810 : INFO : EPOCH 11: training on 17005207 raw words (10000 effective words) took 0.0s, 884359 effective words/s\n",
      "2025-06-10 14:50:29,822 : INFO : EPOCH 12: training on 17005207 raw words (10000 effective words) took 0.0s, 930124 effective words/s\n",
      "2025-06-10 14:50:29,834 : INFO : EPOCH 13: training on 17005207 raw words (10000 effective words) took 0.0s, 901077 effective words/s\n",
      "2025-06-10 14:50:29,845 : INFO : EPOCH 14: training on 17005207 raw words (10000 effective words) took 0.0s, 955776 effective words/s\n",
      "2025-06-10 14:50:29,856 : INFO : EPOCH 15: training on 17005207 raw words (10000 effective words) took 0.0s, 906091 effective words/s\n",
      "2025-06-10 14:50:29,869 : INFO : EPOCH 16: training on 17005207 raw words (10000 effective words) took 0.0s, 976554 effective words/s\n",
      "2025-06-10 14:50:29,881 : INFO : EPOCH 17: training on 17005207 raw words (10000 effective words) took 0.0s, 863524 effective words/s\n",
      "2025-06-10 14:50:29,894 : INFO : EPOCH 18: training on 17005207 raw words (10000 effective words) took 0.0s, 812920 effective words/s\n",
      "2025-06-10 14:50:29,907 : INFO : EPOCH 19: training on 17005207 raw words (10000 effective words) took 0.0s, 820925 effective words/s\n",
      "2025-06-10 14:50:29,908 : INFO : Word2Vec lifecycle event {'msg': 'training on 340104140 raw words (200000 effective words) took 0.2s, 801651 effective words/s', 'datetime': '2025-06-10T14:50:29.908074', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'train'}\n",
      "2025-06-10 14:50:29,908 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=253854, vector_size=100, alpha=0.025>', 'datetime': '2025-06-10T14:50:29.908242', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting CBOW model training...\")\n",
    "cbow_model = Word2Vec(\n",
    "    sentences=sentences_for_gensim,\n",
    "    vector_size=100,      # Example: 100-dimensional word vectors\n",
    "    window=5,             # Consider 5 words before and 5 words after the target word\n",
    "    min_count=1,          # Include all words that appear at least once (for small demo)\n",
    "    sg=0,                 # CRUCIAL: 0 for CBOW, 1 for Skip-gram\n",
    "    workers=4,            # Use 4 CPU cores (adjust based on your system)\n",
    "    epochs=20             # Train for 20 iterations over the dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb3b06a6-4633-427b-b70f-4cfde7d8128e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 14:50:41,340 : INFO : collecting all words and their counts\n",
      "2025-06-10 14:50:41,341 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2025-06-10 14:50:42,232 : INFO : collected 253854 word types from a corpus of 17005207 raw words and 1 sentences\n",
      "2025-06-10 14:50:42,232 : INFO : Creating a fresh vocabulary\n",
      "2025-06-10 14:50:42,447 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 253854 unique words (100.00% of original 253854, drops 0)', 'datetime': '2025-06-10T14:50:42.447085', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2025-06-10 14:50:42,447 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 17005207 word corpus (100.00% of original 17005207, drops 0)', 'datetime': '2025-06-10T14:50:42.447396', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2025-06-10 14:50:42,747 : INFO : deleting the raw counts dictionary of 253854 items\n",
      "2025-06-10 14:50:42,749 : INFO : sample=0.001 downsamples 36 most-common words\n",
      "2025-06-10 14:50:42,750 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 12819131.785650097 word corpus (75.4%% of prior 17005207)', 'datetime': '2025-06-10T14:50:42.750075', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2025-06-10 14:50:43,258 : INFO : estimated required memory for 253854 words and 100 dimensions: 330010200 bytes\n",
      "2025-06-10 14:50:43,258 : INFO : resetting layer weights\n",
      "2025-06-10 14:50:43,313 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-06-10T14:50:43.313729', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'build_vocab'}\n",
      "2025-06-10 14:50:43,314 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 253854 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-06-10T14:50:43.314016', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'train'}\n",
      "2025-06-10 14:50:43,369 : INFO : EPOCH 0: training on 17005207 raw words (10000 effective words) took 0.1s, 184255 effective words/s\n",
      "2025-06-10 14:50:43,411 : INFO : EPOCH 1: training on 17005207 raw words (10000 effective words) took 0.0s, 247959 effective words/s\n",
      "2025-06-10 14:50:43,452 : INFO : EPOCH 2: training on 17005207 raw words (10000 effective words) took 0.0s, 249648 effective words/s\n",
      "2025-06-10 14:50:43,493 : INFO : EPOCH 3: training on 17005207 raw words (10000 effective words) took 0.0s, 246306 effective words/s\n",
      "2025-06-10 14:50:43,535 : INFO : EPOCH 4: training on 17005207 raw words (10000 effective words) took 0.0s, 242032 effective words/s\n",
      "2025-06-10 14:50:43,578 : INFO : EPOCH 5: training on 17005207 raw words (10000 effective words) took 0.0s, 233734 effective words/s\n",
      "2025-06-10 14:50:43,620 : INFO : EPOCH 6: training on 17005207 raw words (10000 effective words) took 0.0s, 245108 effective words/s\n",
      "2025-06-10 14:50:43,672 : INFO : EPOCH 7: training on 17005207 raw words (10000 effective words) took 0.1s, 195873 effective words/s\n",
      "2025-06-10 14:50:43,709 : INFO : EPOCH 8: training on 17005207 raw words (10000 effective words) took 0.0s, 272478 effective words/s\n",
      "2025-06-10 14:50:43,751 : INFO : EPOCH 9: training on 17005207 raw words (10000 effective words) took 0.0s, 243106 effective words/s\n",
      "2025-06-10 14:50:43,792 : INFO : EPOCH 10: training on 17005207 raw words (10000 effective words) took 0.0s, 251038 effective words/s\n",
      "2025-06-10 14:50:43,831 : INFO : EPOCH 11: training on 17005207 raw words (10000 effective words) took 0.0s, 265500 effective words/s\n",
      "2025-06-10 14:50:43,872 : INFO : EPOCH 12: training on 17005207 raw words (10000 effective words) took 0.0s, 252071 effective words/s\n",
      "2025-06-10 14:50:43,915 : INFO : EPOCH 13: training on 17005207 raw words (10000 effective words) took 0.0s, 240224 effective words/s\n",
      "2025-06-10 14:50:43,958 : INFO : EPOCH 14: training on 17005207 raw words (10000 effective words) took 0.0s, 235291 effective words/s\n",
      "2025-06-10 14:50:44,000 : INFO : EPOCH 15: training on 17005207 raw words (10000 effective words) took 0.0s, 243016 effective words/s\n",
      "2025-06-10 14:50:44,040 : INFO : EPOCH 16: training on 17005207 raw words (10000 effective words) took 0.0s, 256134 effective words/s\n",
      "2025-06-10 14:50:44,090 : INFO : EPOCH 17: training on 17005207 raw words (10000 effective words) took 0.0s, 205421 effective words/s\n",
      "2025-06-10 14:50:44,129 : INFO : EPOCH 18: training on 17005207 raw words (10000 effective words) took 0.0s, 261661 effective words/s\n",
      "2025-06-10 14:50:44,169 : INFO : EPOCH 19: training on 17005207 raw words (10000 effective words) took 0.0s, 257035 effective words/s\n",
      "2025-06-10 14:50:44,169 : INFO : Word2Vec lifecycle event {'msg': 'training on 340104140 raw words (200000 effective words) took 0.9s, 233779 effective words/s', 'datetime': '2025-06-10T14:50:44.169680', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'train'}\n",
      "2025-06-10 14:50:44,169 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=253854, vector_size=100, alpha=0.025>', 'datetime': '2025-06-10T14:50:44.169859', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip-gram model training complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "skipgram_model = Word2Vec(\n",
    "    sentences=sentences_for_gensim,\n",
    "    vector_size=100,      # Dimensionality of the word vectors\n",
    "    window=5,             # Context window size\n",
    "    min_count=1,          # Minimum frequency for words to be included\n",
    "    sg=1,                 # CRUCIAL: 1 for Skip-gram\n",
    "    workers=4,            # Number of worker threads\n",
    "    epochs=20             # Number of iterations over the dataset\n",
    ")\n",
    "print(\"Skip-gram model training complete.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54047d4b-8d6e-415b-96be-2952881f1629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CBOW Model Queries ---\n",
      "\n",
      "Querying Word Vectors (CBOW):\n",
      "Vector for 'fox' (CBOW, first 5 elements):\n",
      "[ 0.0079074   0.00659146  0.0093744  -0.00740751  0.00027037]...\n",
      "\n",
      "Finding Similar Words (CBOW):\n",
      "Words similar to 'learning' (CBOW): [('at', 0.9988629221916199), ('or', 0.9987952709197998), ('movements', 0.9987720847129822)]\n",
      "\n",
      "Performing Analogies (CBOW):\n",
      "Analogy (CBOW): 'quick' + 'fox' - 'brown' = [('mozarteum', 0.41852787137031555)]\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Using the Trained Models (CBOW and Skip-gram) ---\n",
    "\n",
    "# --- CBOW Model Queries ---\n",
    "print(\"\\n--- CBOW Model Queries ---\")\n",
    "try:\n",
    "    print(\"\\nQuerying Word Vectors (CBOW):\")\n",
    "    word_vector_fox_cbow = cbow_model.wv['fox']\n",
    "    print(f\"Vector for 'fox' (CBOW, first 5 elements):\\n{word_vector_fox_cbow[:5]}...\")\n",
    "except KeyError:\n",
    "    print(\"Word 'fox' not found in CBOW vocabulary.\")\n",
    "\n",
    "try:\n",
    "    print(\"\\nFinding Similar Words (CBOW):\")\n",
    "    similar_to_learning_cbow = cbow_model.wv.most_similar('learning', topn=3)\n",
    "    print(f\"Words similar to 'learning' (CBOW): {similar_to_learning_cbow}\")\n",
    "except KeyError:\n",
    "    print(\"Word 'learning' not found in CBOW vocabulary.\")\n",
    "\n",
    "try:\n",
    "    print(\"\\nPerforming Analogies (CBOW):\")\n",
    "    # Example: 'cat' - 'animal' + 'fruit' = ? (might not work well with small data)\n",
    "    analogy_result_cbow = cbow_model.wv.most_similar(positive=['quick', 'fox'], negative=['brown'], topn=1)\n",
    "    print(f\"Analogy (CBOW): 'quick' + 'fox' - 'brown' = {analogy_result_cbow}\")\n",
    "except KeyError:\n",
    "    print(\"One or more words for analogy not found in CBOW vocabulary.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not perform CBOW analogy due to: {e}. (Common with very small training data).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9fbce9e-7c3a-4de1-b673-90187243dafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Skip-gram Model Queries ---\n",
      "\n",
      "Querying Word Vectors (Skip-gram):\n",
      "Vector for 'fox' (Skip-gram, first 5 elements):\n",
      "[ 0.0079074   0.00659146  0.0093744  -0.00740751  0.00027037]...\n",
      "\n",
      "Finding Similar Words (Skip-gram):\n",
      "Words similar to 'learning' (Skip-gram): [('childhood', 0.9991598725318909), ('typical', 0.9990558624267578), ('force', 0.9990442395210266)]\n",
      "\n",
      "Performing Analogies (Skip-gram):\n",
      "Analogy (Skip-gram): 'quick' + 'fox' - 'brown' = [('mozarteum', 0.41852787137031555)]\n"
     ]
    }
   ],
   "source": [
    "# --- Skip-gram Model Queries ---\n",
    "print(\"\\n--- Skip-gram Model Queries ---\")\n",
    "try:\n",
    "    print(\"\\nQuerying Word Vectors (Skip-gram):\")\n",
    "    word_vector_fox_skipgram = skipgram_model.wv['fox']\n",
    "    print(f\"Vector for 'fox' (Skip-gram, first 5 elements):\\n{word_vector_fox_skipgram[:5]}...\")\n",
    "except KeyError:\n",
    "    print(\"Word 'fox' not found in Skip-gram vocabulary.\")\n",
    "\n",
    "try:\n",
    "    print(\"\\nFinding Similar Words (Skip-gram):\")\n",
    "    similar_to_learning_skipgram = skipgram_model.wv.most_similar('learning', topn=3)\n",
    "    print(f\"Words similar to 'learning' (Skip-gram): {similar_to_learning_skipgram}\")\n",
    "except KeyError:\n",
    "    print(\"Word 'learning' not found in Skip-gram vocabulary.\")\n",
    "\n",
    "try:\n",
    "    print(\"\\nPerforming Analogies (Skip-gram):\")\n",
    "    analogy_result_skipgram = skipgram_model.wv.most_similar(positive=['quick', 'fox'], negative=['brown'], topn=1)\n",
    "    print(f\"Analogy (Skip-gram): 'quick' + 'fox' - 'brown' = {analogy_result_skipgram}\")\n",
    "except KeyError:\n",
    "    print(\"One or more words for analogy not found in Skip-gram vocabulary.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not perform Skip-gram analogy due to: {e}. (Common with very small training data).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27956ebc-efe8-4f58-85b5-965ad448b7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 14:56:55,272 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'cbow_word2vec_model_pandas.bin', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-06-10T14:56:55.271947', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'saving'}\n",
      "2025-06-10 14:56:55,273 : INFO : storing np array 'vectors' to cbow_word2vec_model_pandas.bin.wv.vectors.npy\n",
      "2025-06-10 14:56:55,299 : INFO : storing np array 'syn1neg' to cbow_word2vec_model_pandas.bin.syn1neg.npy\n",
      "2025-06-10 14:56:55,328 : INFO : not storing attribute cum_table\n",
      "2025-06-10 14:56:55,485 : INFO : saved cbow_word2vec_model_pandas.bin\n",
      "2025-06-10 14:56:55,485 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'skipgram_word2vec_model_pandas.bin', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-06-10T14:56:55.485579', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'saving'}\n",
      "2025-06-10 14:56:55,485 : INFO : storing np array 'vectors' to skipgram_word2vec_model_pandas.bin.wv.vectors.npy\n",
      "2025-06-10 14:56:55,505 : INFO : storing np array 'syn1neg' to skipgram_word2vec_model_pandas.bin.syn1neg.npy\n",
      "2025-06-10 14:56:55,526 : INFO : not storing attribute cum_table\n",
      "2025-06-10 14:56:55,570 : INFO : saved skipgram_word2vec_model_pandas.bin\n",
      "2025-06-10 14:56:55,570 : INFO : loading Word2Vec object from cbow_word2vec_model_pandas.bin\n",
      "2025-06-10 14:56:55,596 : INFO : loading wv recursively from cbow_word2vec_model_pandas.bin.wv.* with mmap=None\n",
      "2025-06-10 14:56:55,596 : INFO : loading vectors from cbow_word2vec_model_pandas.bin.wv.vectors.npy with mmap=None\n",
      "2025-06-10 14:56:55,607 : INFO : loading syn1neg from cbow_word2vec_model_pandas.bin.syn1neg.npy with mmap=None\n",
      "2025-06-10 14:56:55,618 : INFO : setting ignored attribute cum_table to None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CBOW model saved to cbow_word2vec_model_pandas.bin\n",
      "Skip-gram model saved to skipgram_word2vec_model_pandas.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 14:56:56,082 : INFO : Word2Vec lifecycle event {'fname': 'cbow_word2vec_model_pandas.bin', 'datetime': '2025-06-10T14:56:56.082428', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'loaded'}\n",
      "2025-06-10 14:56:56,082 : INFO : loading Word2Vec object from skipgram_word2vec_model_pandas.bin\n",
      "2025-06-10 14:56:56,105 : INFO : loading wv recursively from skipgram_word2vec_model_pandas.bin.wv.* with mmap=None\n",
      "2025-06-10 14:56:56,105 : INFO : loading vectors from skipgram_word2vec_model_pandas.bin.wv.vectors.npy with mmap=None\n",
      "2025-06-10 14:56:56,116 : INFO : loading syn1neg from skipgram_word2vec_model_pandas.bin.syn1neg.npy with mmap=None\n",
      "2025-06-10 14:56:56,127 : INFO : setting ignored attribute cum_table to None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW model loaded from cbow_word2vec_model_pandas.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 14:56:56,594 : INFO : Word2Vec lifecycle event {'fname': 'skipgram_word2vec_model_pandas.bin', 'datetime': '2025-06-10T14:56:56.594725', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip-gram model loaded from skipgram_word2vec_model_pandas.bin\n",
      "Vector for 'ai' from loaded CBOW model (first 5 elements):\n",
      "[-0.0085533   0.00892655  0.00210113 -0.00927936 -0.00496012]...\n",
      "Vector for 'ai' from loaded Skip-gram model (first 5 elements):\n",
      "[-0.0085533   0.00892655  0.00210113 -0.00927936 -0.00496012]...\n"
     ]
    }
   ],
   "source": [
    "# --- 8. Save and Load the Models (Optional) ---\n",
    "# Saving the models allows you to reuse them later without retraining.\n",
    "cbow_model_path = 'cbow_word2vec_model_pandas.bin'\n",
    "skipgram_model_path = 'skipgram_word2vec_model_pandas.bin'\n",
    "\n",
    "cbow_model.save(cbow_model_path)\n",
    "print(f\"\\nCBOW model saved to {cbow_model_path}\")\n",
    "\n",
    "skipgram_model.save(skipgram_model_path)\n",
    "print(f\"Skip-gram model saved to {skipgram_model_path}\")\n",
    "\n",
    "# Load the models back\n",
    "loaded_cbow_model = Word2Vec.load(cbow_model_path)\n",
    "print(f\"CBOW model loaded from {cbow_model_path}\")\n",
    "\n",
    "loaded_skipgram_model = Word2Vec.load(skipgram_model_path)\n",
    "print(f\"Skip-gram model loaded from {skipgram_model_path}\")\n",
    "\n",
    "# Verify by checking a vector from the loaded models\n",
    "try:\n",
    "    loaded_word_vector_ai_cbow = loaded_cbow_model.wv['ai']\n",
    "    print(f\"Vector for 'ai' from loaded CBOW model (first 5 elements):\\n{loaded_word_vector_ai_cbow[:5]}...\")\n",
    "except KeyError:\n",
    "    print(\"Word 'ai' not found in CBOW vocabulary (after loading).\")\n",
    "\n",
    "try:\n",
    "    loaded_word_vector_ai_skipgram = loaded_skipgram_model.wv['ai']\n",
    "    print(f\"Vector for 'ai' from loaded Skip-gram model (first 5 elements):\\n{loaded_word_vector_ai_skipgram[:5]}...\")\n",
    "except KeyError:\n",
    "    print(\"Word 'ai' not found in Skip-gram vocabulary (after loading).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86198aa-65c2-409d-8e32-621d5460207a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
