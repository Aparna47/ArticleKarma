{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6cd12fc-baa1-424e-9b31-d4f0127ee278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gensim.downloader as api\n",
    "import re\n",
    "import os\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# For Hacker News dataset\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pandas as pd\n",
    "torch.set_num_threads(8)  # or up to 10 for M4\n",
    "torch.set_num_interop_threads(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb350792-b9d4-4343-bcd4-35cf84c255a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mclemha\u001b[0m (\u001b[33mclemha-mli\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/clementha/Documents/MLX1/ArticleKarma/wandb/run-20250612_164420-kwratr9y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/clemha-mli/HackerNews%20Prediction/runs/kwratr9y' target=\"_blank\">fresh-field-3</a></strong> to <a href='https://wandb.ai/clemha-mli/HackerNews%20Prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/clemha-mli/HackerNews%20Prediction' target=\"_blank\">https://wandb.ai/clemha-mli/HackerNews%20Prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/clemha-mli/HackerNews%20Prediction/runs/kwratr9y' target=\"_blank\">https://wandb.ai/clemha-mli/HackerNews%20Prediction/runs/kwratr9y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Integration with W&B\n",
    "import random\n",
    "import wandb\n",
    "run = wandb.init(\n",
    "    # Set the wandb entity where your project will be logged (generally your team name).\n",
    "    entity=\"clemha-mli\",\n",
    "    # Set the wandb project where this run will be logged.\n",
    "    project=\"HackerNews Prediction\",\n",
    "    # Track hyperparameters and run metadata.\n",
    "    config={\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"architecture\": \"MLP with 2 hidden layers (64, 32)\",\n",
    "        \"dataset\": \"Hackernews text and text length\",\n",
    "        \"epochs\": 30,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1e65f13-e159-4408-8940-698958eb0f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"Inputs1stGen.csv\", low_memory = False, nrows=100000)\n",
    "# Scale the score to 0 to 1\n",
    "df = df.dropna()\n",
    "scaler = MinMaxScaler()\n",
    "df['score_scaled'] = scaler.fit_transform(df[['score']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "392656e7-19f7-4eed-91b5-242bc18885f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved GloVe model from disk...\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load GloVe 100 model (download once, save for reuse)\n",
    "model_path = \"glove-wiki-gigaword-100.kv\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Loading saved GloVe model from disk...\")\n",
    "    glove = KeyedVectors.load(model_path, mmap='r')\n",
    "else:\n",
    "    print(\"Downloading GloVe model...\")\n",
    "    glove = api.load(\"glove-wiki-gigaword-100\")\n",
    "    glove.save(model_path)\n",
    "\n",
    "embedding_dim = glove.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ce050b2-29ac-4c90-9916-544ba9774af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Sentence preprocessing + vector averaging\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    return re.findall(r'\\b\\w+\\b', text)\n",
    "\n",
    "def sentence_to_vec_and_len(sentence, model, dim):\n",
    "    tokens = preprocess(sentence)\n",
    "    vectors = [model[word] for word in tokens if word in model.key_to_index]\n",
    "    if not vectors:\n",
    "        return np.zeros(dim), 0\n",
    "    return np.mean(vectors, axis=0), len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d294b75-11c8-4e20-ae6e-f332002e1575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Vectorise sentences and get lengths\n",
    "vectors = []\n",
    "sentence_lengths = []\n",
    "#for sent in data['sentence']:\n",
    "for sent in df['title']:\n",
    "    vec, length = sentence_to_vec_and_len(sent, glove, embedding_dim)\n",
    "    vectors.append(vec)\n",
    "    sentence_lengths.append(length)\n",
    "\n",
    "df['vector'] = vectors\n",
    "df['length'] = sentence_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d379098-c023-417c-91f6-550f53604a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Custom Dataset with sentence length\n",
    "class SentenceScoreDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.X_embed = torch.tensor(np.stack(df['vector'].values), dtype=torch.float32)\n",
    "        self.X_len = torch.tensor(df['length'].values, dtype=torch.float32).view(-1, 1)\n",
    "        self.X = torch.cat([self.X_embed, self.X_len], dim=1)\n",
    "        self.y = torch.tensor(df['score_scaled'].values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d694c9cc-ee61-450e-a57f-5c1f6c751d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Split and prepare DataLoader\n",
    "#train_df, temp_df = train_test_split(data, test_size=0.4, random_state=42)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.4, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "train_ds = SentenceScoreDataset(train_df)\n",
    "val_ds = SentenceScoreDataset(val_df)\n",
    "test_ds = SentenceScoreDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=2)\n",
    "test_loader = DataLoader(test_ds, batch_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57d1d425-83d9-4031-b605-f75c918d29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: MLP Regression Model\n",
    "class MLPRegressor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = MLPRegressor(embedding_dim + 1)  # +1 for sentence length\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=wandb.config['learning_rate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0711bb12-64d2-4f6b-9e66-42f507c211b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.watch(model, log='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61d29244-7f9b-4697-9c43-737469810bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 17.6089, Val Loss: 0.0006, R2: -0.0210, MAE: 0.0075\n",
      "Epoch 2/30, Train Loss: 14.7942, Val Loss: 0.0006, R2: 0.0019, MAE: 0.0098\n",
      "Epoch 3/30, Train Loss: 14.6121, Val Loss: 0.0006, R2: 0.0062, MAE: 0.0085\n",
      "Epoch 4/30, Train Loss: 14.5218, Val Loss: 0.0006, R2: 0.0074, MAE: 0.0088\n",
      "Epoch 5/30, Train Loss: 14.4599, Val Loss: 0.0006, R2: 0.0048, MAE: 0.0084\n",
      "Epoch 6/30, Train Loss: 14.3959, Val Loss: 0.0006, R2: 0.0017, MAE: 0.0074\n",
      "Epoch 7/30, Train Loss: 14.3288, Val Loss: 0.0006, R2: 0.0018, MAE: 0.0097\n",
      "Epoch 8/30, Train Loss: 14.2771, Val Loss: 0.0006, R2: 0.0059, MAE: 0.0080\n",
      "Epoch 9/30, Train Loss: 14.1600, Val Loss: 0.0006, R2: 0.0026, MAE: 0.0080\n",
      "Epoch 10/30, Train Loss: 14.0237, Val Loss: 0.0006, R2: -0.0112, MAE: 0.0074\n",
      "Epoch 11/30, Train Loss: 13.8709, Val Loss: 0.0006, R2: -0.0103, MAE: 0.0073\n",
      "Epoch 12/30, Train Loss: 13.7443, Val Loss: 0.0006, R2: -0.0074, MAE: 0.0088\n",
      "Epoch 13/30, Train Loss: 13.5307, Val Loss: 0.0006, R2: -0.0133, MAE: 0.0080\n",
      "Epoch 14/30, Train Loss: 13.2615, Val Loss: 0.0006, R2: -0.0198, MAE: 0.0102\n",
      "Epoch 15/30, Train Loss: 13.0346, Val Loss: 0.0006, R2: -0.0264, MAE: 0.0074\n",
      "Epoch 16/30, Train Loss: 12.8014, Val Loss: 0.0006, R2: -0.0166, MAE: 0.0086\n",
      "Epoch 17/30, Train Loss: 12.5401, Val Loss: 0.0006, R2: -0.0570, MAE: 0.0089\n",
      "Epoch 18/30, Train Loss: 12.2707, Val Loss: 0.0006, R2: -0.0583, MAE: 0.0085\n",
      "Epoch 19/30, Train Loss: 12.0331, Val Loss: 0.0006, R2: -0.0206, MAE: 0.0081\n",
      "Epoch 20/30, Train Loss: 11.7872, Val Loss: 0.0006, R2: -0.0460, MAE: 0.0085\n",
      "Epoch 21/30, Train Loss: 11.7823, Val Loss: 0.0006, R2: -0.0466, MAE: 0.0085\n",
      "Epoch 22/30, Train Loss: 11.7129, Val Loss: 0.0006, R2: -0.0212, MAE: 0.0082\n",
      "Epoch 23/30, Train Loss: 11.4790, Val Loss: 0.0006, R2: -0.0314, MAE: 0.0084\n",
      "Epoch 24/30, Train Loss: 11.4905, Val Loss: 0.0006, R2: -0.0227, MAE: 0.0084\n",
      "Epoch 25/30, Train Loss: 11.3406, Val Loss: 0.0006, R2: -0.0328, MAE: 0.0086\n",
      "Epoch 26/30, Train Loss: 11.1187, Val Loss: 0.0006, R2: -0.0416, MAE: 0.0078\n",
      "Epoch 27/30, Train Loss: 11.2193, Val Loss: 0.0006, R2: -0.0457, MAE: 0.0078\n",
      "Epoch 28/30, Train Loss: 10.9167, Val Loss: 0.0006, R2: -0.0196, MAE: 0.0091\n",
      "Epoch 29/30, Train Loss: 11.0698, Val Loss: 0.0006, R2: -0.0600, MAE: 0.0084\n",
      "Epoch 30/30, Train Loss: 10.8847, Val Loss: 0.0007, R2: -0.1280, MAE: 0.0083\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Training Loop with Validation\n",
    "epochs = wandb.config[\"epochs\"]\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_loader:\n",
    "            preds = model(X_val)\n",
    "            val_loss += criterion(preds, y_val).item()\n",
    "            y_true.extend(y_val.numpy())\n",
    "            y_pred.extend(preds.numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {total_loss:.4f}, Val Loss: {avg_val_loss:.4f}, R2: {r2:.4f}, MAE: {mae:.4f}\")\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": total_loss / len(train_loader),\n",
    "        \"val_loss\": avg_val_loss,\n",
    "        \"val_r2\": r2,\n",
    "        \"val_mae\": mae\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c26afa36-c0fb-4fd3-9098-1dcbc0ee4148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results: R2: -0.1185, MAE: 0.0080, MSE: 0.0006\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Final Test Evaluation\n",
    "model.eval()\n",
    "y_true_test, y_pred_test = [], []\n",
    "with torch.no_grad():\n",
    "    for X_test, y_test in test_loader:\n",
    "        preds = model(X_test)\n",
    "        y_true_test.extend(y_test.numpy())\n",
    "        y_pred_test.extend(preds.numpy())\n",
    "        \n",
    "r2_test = r2_score(y_true_test, y_pred_test)\n",
    "mae_test = mean_absolute_error(y_true_test, y_pred_test)\n",
    "mse_test = np.mean((np.array(y_true_test) - np.array(y_pred_test)) ** 2)\n",
    "\n",
    "print(f\"\\nTest Results: R2: {r2_test:.4f}, MAE: {mae_test:.4f}, MSE: {mse_test:.4f}\")\n",
    "wandb.log({\n",
    "    \"test_r2\": r2_test,\n",
    "    \"test_mae\": mae_test,\n",
    "    \"test_mse\": mse_test\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63599c92-d18d-45f3-9102-e680a1e30392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Show sample predictions\n",
    "# print(\"\\nSample Predictions:\")\n",
    "# for true, pred in zip(y_true_test, y_pred_test):\n",
    "#     print(f\"True: {true[0]:.2f}, Predicted: {pred[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4c20ab4-c00d-4277-a49c-b824f2726ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score Prediction from New Sentence:\n",
      "Sentence: Elon Musk just died.\n",
      "Predicted Score: 7.1863\n"
     ]
    }
   ],
   "source": [
    "# Step 12: Generate a score from custom sentence\n",
    "print(\"\\nScore Prediction from New Sentence:\")\n",
    "custom_sentence = \"Elon Musk just died.\"\n",
    "vec, length = sentence_to_vec_and_len(custom_sentence, glove, embedding_dim)\n",
    "input_tensor = torch.tensor(np.append(vec, length), dtype=torch.float32).unsqueeze(0)  # shape (1, dim+1)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    scaled_pred = model(input_tensor).item()\n",
    "    predicted_score = scaler.inverse_transform([[scaled_pred]])[0][0]\n",
    "    print(f\"Sentence: {custom_sentence}\\nPredicted Score: {predicted_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed12ec5f-0d52-4450-889d-437bb361af2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
